import {
  Fn,
  If,
  Loop,
  add,
  clamp,
  convertToTexture,
  float,
  getViewPosition,
  int,
  length,
  luminance,
  max,
  min,
  nodeObject,
  passTexture,
  texture,
  uniform,
  uv,
  vec2,
  vec4,
  velocity
} from "./chunk-KPFVNXSK.js";
import {
  NodeMaterial,
  NodeUpdateType,
  QuadMesh,
  RendererUtils,
  TempNode
} from "./chunk-IDAOASVO.js";
import {
  DepthTexture,
  HalfFloatType,
  Matrix4,
  RenderTarget,
  Vector2
} from "./chunk-XFHY3IS3.js";

// node_modules/three/examples/jsm/tsl/display/TRAANode.js
var _quadMesh = new QuadMesh();
var _size = new Vector2();
var _rendererState;
var TRAANode = class extends TempNode {
  static get type() {
    return "TRAANode";
  }
  /**
   * Constructs a new TRAA node.
   *
   * @param {TextureNode} beautyNode - The texture node that represents the input of the effect.
   * @param {TextureNode} depthNode - A node that represents the scene's depth.
   * @param {TextureNode} velocityNode - A node that represents the scene's velocity.
   * @param {Camera} camera - The camera the scene is rendered with.
   */
  constructor(beautyNode, depthNode, velocityNode, camera) {
    super("vec4");
    this.isTRAANode = true;
    this.updateBeforeType = NodeUpdateType.FRAME;
    this.beautyNode = beautyNode;
    this.depthNode = depthNode;
    this.velocityNode = velocityNode;
    this.camera = camera;
    this._jitterIndex = 0;
    this._invSize = uniform(new Vector2());
    this._cameraWorldMatrix = uniform(new Matrix4());
    this._cameraProjectionMatrixInverse = uniform(new Matrix4());
    this._previousCameraWorldMatrix = uniform(new Matrix4());
    this._previousCameraProjectionMatrixInverse = uniform(new Matrix4());
    this._historyRenderTarget = new RenderTarget(1, 1, { depthBuffer: false, type: HalfFloatType, depthTexture: new DepthTexture() });
    this._historyRenderTarget.texture.name = "TRAANode.history";
    this._resolveRenderTarget = new RenderTarget(1, 1, { depthBuffer: false, type: HalfFloatType });
    this._resolveRenderTarget.texture.name = "TRAANode.resolve";
    this._resolveMaterial = new NodeMaterial();
    this._resolveMaterial.name = "TRAA.resolve";
    this._textureNode = passTexture(this, this._resolveRenderTarget.texture);
    this._originalProjectionMatrix = new Matrix4();
    this._previousDepthNode = texture(new DepthTexture(1, 1));
    this._needsPostProcessingSync = false;
  }
  /**
   * Returns the result of the effect as a texture node.
   *
   * @return {PassTextureNode} A texture node that represents the result of the effect.
   */
  getTextureNode() {
    return this._textureNode;
  }
  /**
   * Sets the size of the effect.
   *
   * @param {number} width - The width of the effect.
   * @param {number} height - The height of the effect.
   */
  setSize(width, height) {
    this._historyRenderTarget.setSize(width, height);
    this._resolveRenderTarget.setSize(width, height);
    this._invSize.value.set(1 / width, 1 / height);
  }
  /**
   * Defines the TRAA's current jitter as a view offset
   * to the scene's camera.
   *
   * @param {number} width - The width of the effect.
   * @param {number} height - The height of the effect.
   */
  setViewOffset(width, height) {
    this.camera.updateProjectionMatrix();
    this._originalProjectionMatrix.copy(this.camera.projectionMatrix);
    velocity.setProjectionMatrix(this._originalProjectionMatrix);
    const viewOffset = {
      fullWidth: width,
      fullHeight: height,
      offsetX: 0,
      offsetY: 0,
      width,
      height
    };
    const jitterOffset = _JitterVectors[this._jitterIndex];
    this.camera.setViewOffset(
      viewOffset.fullWidth,
      viewOffset.fullHeight,
      viewOffset.offsetX + jitterOffset[0] * 0.0625,
      viewOffset.offsetY + jitterOffset[1] * 0.0625,
      // 0.0625 = 1 / 16
      viewOffset.width,
      viewOffset.height
    );
  }
  /**
   * Clears the view offset from the scene's camera.
   */
  clearViewOffset() {
    this.camera.clearViewOffset();
    velocity.setProjectionMatrix(null);
    this._jitterIndex++;
    this._jitterIndex = this._jitterIndex % (_JitterVectors.length - 1);
  }
  /**
   * This method is used to render the effect once per frame.
   *
   * @param {NodeFrame} frame - The current node frame.
   */
  updateBefore(frame) {
    const { renderer } = frame;
    this._previousCameraWorldMatrix.value.copy(this._cameraWorldMatrix.value);
    this._previousCameraProjectionMatrixInverse.value.copy(this._cameraProjectionMatrixInverse.value);
    this._cameraWorldMatrix.value.copy(this.camera.matrixWorld);
    this._cameraProjectionMatrixInverse.value.copy(this.camera.projectionMatrixInverse);
    const beautyRenderTarget = this.beautyNode.isRTTNode ? this.beautyNode.renderTarget : this.beautyNode.passNode.renderTarget;
    const width = beautyRenderTarget.texture.width;
    const height = beautyRenderTarget.texture.height;
    if (this._needsPostProcessingSync === true) {
      this.setViewOffset(width, height);
      this._needsPostProcessingSync = false;
    }
    _rendererState = RendererUtils.resetRendererState(renderer, _rendererState);
    const needsRestart = this._historyRenderTarget.width !== width || this._historyRenderTarget.height !== height;
    this.setSize(width, height);
    if (needsRestart === true) {
      renderer.setRenderTarget(this._historyRenderTarget);
      renderer.clear();
      renderer.setRenderTarget(this._resolveRenderTarget);
      renderer.clear();
      renderer.copyTextureToTexture(beautyRenderTarget.texture, this._historyRenderTarget.texture);
    }
    renderer.setRenderTarget(this._resolveRenderTarget);
    _quadMesh.material = this._resolveMaterial;
    _quadMesh.name = "TRAA";
    _quadMesh.render(renderer);
    renderer.setRenderTarget(null);
    renderer.copyTextureToTexture(this._resolveRenderTarget.texture, this._historyRenderTarget.texture);
    const size = renderer.getDrawingBufferSize(_size);
    if (this._historyRenderTarget.height === size.height && this._historyRenderTarget.width === size.width) {
      const currentDepth = this.depthNode.value;
      renderer.copyTextureToTexture(currentDepth, this._historyRenderTarget.depthTexture);
      this._previousDepthNode.value = this._historyRenderTarget.depthTexture;
    }
    RendererUtils.restoreRendererState(renderer, _rendererState);
  }
  /**
   * This method is used to setup the effect's render targets and TSL code.
   *
   * @param {NodeBuilder} builder - The current node builder.
   * @return {PassTextureNode}
   */
  setup(builder) {
    const postProcessing = builder.context.postProcessing;
    if (postProcessing) {
      this._needsPostProcessingSync = true;
      postProcessing.context.onBeforePostProcessing = () => {
        const size = builder.renderer.getDrawingBufferSize(_size);
        this.setViewOffset(size.width, size.height);
      };
      postProcessing.context.onAfterPostProcessing = () => {
        this.clearViewOffset();
      };
    }
    const historyTexture = texture(this._historyRenderTarget.texture);
    const sampleTexture = this.beautyNode;
    const depthTexture = this.depthNode;
    const velocityTexture = this.velocityNode;
    const resolve = Fn(() => {
      const uvNode = uv();
      const minColor = vec4(1e4).toVar();
      const maxColor = vec4(-1e4).toVar();
      const closestDepth = float(1).toVar();
      const farthestDepth = float(0).toVar();
      const closestDepthPixelPosition = vec2(0).toVar();
      Loop({ start: int(-1), end: int(1), type: "int", condition: "<=", name: "x" }, ({ x }) => {
        Loop({ start: int(-1), end: int(1), type: "int", condition: "<=", name: "y" }, ({ y }) => {
          const uvNeighbor = uvNode.add(vec2(float(x), float(y)).mul(this._invSize)).toVar();
          const colorNeighbor = max(vec4(0), sampleTexture.sample(uvNeighbor)).toVar();
          minColor.assign(min(minColor, colorNeighbor));
          maxColor.assign(max(maxColor, colorNeighbor));
          const currentDepth2 = depthTexture.sample(uvNeighbor).r.toVar();
          If(currentDepth2.lessThan(closestDepth), () => {
            closestDepth.assign(currentDepth2);
            closestDepthPixelPosition.assign(uvNeighbor);
          });
          If(currentDepth2.greaterThan(farthestDepth), () => {
            farthestDepth.assign(currentDepth2);
          });
        });
      });
      const offset = velocityTexture.sample(closestDepthPixelPosition).xy.mul(vec2(0.5, -0.5));
      const currentColor = sampleTexture.sample(uvNode);
      const historyColor = historyTexture.sample(uvNode.sub(offset));
      const clampedHistoryColor = clamp(historyColor, minColor, maxColor);
      const currentDepth = depthTexture.sample(uvNode).r;
      const currentViewPosition = getViewPosition(uvNode, currentDepth, this._cameraProjectionMatrixInverse);
      const currentWorldPosition = this._cameraWorldMatrix.mul(vec4(currentViewPosition, 1)).xyz;
      const historyUV = uvNode.sub(offset);
      const previousDepth = this._previousDepthNode.sample(historyUV).r;
      const previousViewPosition = getViewPosition(historyUV, previousDepth, this._previousCameraProjectionMatrixInverse);
      const previousWorldPosition = this._previousCameraWorldMatrix.mul(vec4(previousViewPosition, 1)).xyz;
      const worldPositionDifference = length(currentWorldPosition.sub(previousWorldPosition)).toVar();
      worldPositionDifference.assign(min(max(worldPositionDifference.sub(1), 0), 1));
      const velocityMagnitude = length(offset).toConst();
      const motionFactor = max(worldPositionDifference.mul(0.5), velocityMagnitude.mul(10)).toVar();
      motionFactor.assign(min(motionFactor, 1));
      const currentWeight = float(0.05).add(motionFactor.mul(0.25)).toVar();
      const historyWeight = currentWeight.oneMinus().toVar();
      const isEdge = farthestDepth.sub(closestDepth).greaterThan(1e-5);
      const strongDisocclusion = worldPositionDifference.greaterThan(0.5).and(isEdge.not());
      If(strongDisocclusion, () => {
        currentWeight.assign(1);
        historyWeight.assign(0);
      });
      const compressedCurrent = currentColor.mul(float(1).div(max(currentColor.r, currentColor.g, currentColor.b).add(1)));
      const compressedHistory = clampedHistoryColor.mul(float(1).div(max(clampedHistoryColor.r, clampedHistoryColor.g, clampedHistoryColor.b).add(1)));
      const luminanceCurrent = luminance(compressedCurrent.rgb);
      const luminanceHistory = luminance(compressedHistory.rgb);
      currentWeight.mulAssign(float(1).div(luminanceCurrent.add(1)));
      historyWeight.mulAssign(float(1).div(luminanceHistory.add(1)));
      const smoothedOutput = add(currentColor.mul(currentWeight), clampedHistoryColor.mul(historyWeight)).div(max(currentWeight.add(historyWeight), 1e-5)).toVar();
      return smoothedOutput;
    });
    this._resolveMaterial.colorNode = resolve();
    return this._textureNode;
  }
  /**
   * Frees internal resources. This method should be called
   * when the effect is no longer required.
   */
  dispose() {
    this._historyRenderTarget.dispose();
    this._resolveRenderTarget.dispose();
    this._resolveMaterial.dispose();
  }
};
var TRAANode_default = TRAANode;
var _JitterVectors = [
  [-4, -7],
  [-7, -5],
  [-3, -5],
  [-5, -4],
  [-1, -4],
  [-2, -2],
  [-6, -1],
  [-4, 0],
  [-7, 1],
  [-1, 2],
  [-6, 3],
  [-3, 3],
  [-7, 6],
  [-3, 6],
  [-5, 7],
  [-1, 7],
  [5, -7],
  [1, -6],
  [6, -5],
  [4, -4],
  [2, -3],
  [7, -2],
  [1, -1],
  [4, -1],
  [2, 1],
  [6, 2],
  [0, 4],
  [4, 4],
  [2, 5],
  [7, 5],
  [5, 6],
  [3, 7]
];
var traa = (beautyNode, depthNode, velocityNode, camera) => nodeObject(new TRAANode(convertToTexture(beautyNode), depthNode, velocityNode, camera));
export {
  TRAANode_default as default,
  traa
};
//# sourceMappingURL=three_addons_tsl_display_TRAANode__js.js.map
